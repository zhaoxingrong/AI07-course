{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入停用词\n",
    "global stop_list\n",
    "stop_list=list(set(pd.read_table('chinese-stopword.txt',sep='\\t',names=['stop'])['stop']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_chinese(uchar):\n",
    "#   判断一个unicode是否是汉字\n",
    "    if uchar >= u'\\u4e00' and uchar <= u'\\u9fa5':\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_df():\n",
    "#   获取正负例dataframe 和 停用词list\n",
    "    neg_df=pd.read_table('neg.txt',sep='\\t',names=['label','chat'])\n",
    "    pos_df=pd.read_table('pos.txt',sep='\\t',names=['label','chat'])\n",
    "    stop_list=list(set(pd.read_table('chinese-stopword.txt',sep='\\t',names=['stop'])['stop']))\n",
    "    return neg_df,pos_df,stop_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jieba_getdata(str_str,stopwords=stop_list):\n",
    "#   结巴切词\n",
    "    cut_list=jieba.lcut(str_str)\n",
    "    cut_list=[iword for iword in cut_list if iword not in stopwords] #过滤停用词\n",
    "    cut_list=[iword for iword in cut_list if is_chinese(iword) is True] #过滤非中文字符\n",
    "    cut_str=' '.join(cut_list) #空格连接\n",
    "    return cut_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jieba_getdata_adjective(str_str,stopwords=stop_list):\n",
    "#   利用结巴词性标注的选取形容词\n",
    "    words=pseg.cut(str_str)\n",
    "    cut_list=[i.word for i in words if i.flag=='a'] #选择分词后的形容词\n",
    "    cut_list=[iword for iword in cut_list if iword not in stopwords]\n",
    "    cut_list=[iword for iword in cut_list if is_chinese(iword) is True]\n",
    "    cut_str=' '.join(cut_list)\n",
    "    return cut_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cut_word(method_select):\n",
    "#   选取两种方式进行切词 : jieba_getdata_adjective or jieba_getdata\n",
    "    neg_df,pos_df,stop_list = get_data_df()\n",
    "    neg_df['cut']=neg_df['chat'].map(str).apply(method_select)\n",
    "    del neg_df['chat']\n",
    "    pos_df['cut']=pos_df['chat'].map(str).apply(method_select)\n",
    "    del pos_df['chat']\n",
    "    return neg_df,pos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xdata_label(method_select):\n",
    "#   词频特征的向量化\n",
    "    neg_df,pos_df = get_cut_word(method_select)\n",
    "    xdata=[]\n",
    "    ylabel=[]\n",
    "    neg_pos = pd.concat([neg_df,pos_df])\n",
    "    for i in range(len(neg_pos)):\n",
    "        ixdata = neg_pos.iloc[i,1]\n",
    "        ilabel = neg_pos.iloc[i,0]\n",
    "        if ixdata!='':\n",
    "            xdata.append(ixdata)\n",
    "            ylabel.append(ilabel)\n",
    "    return xdata,ylabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_df,pos_df,stop_list = get_data_df() #获取正负样本数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/_t/wschnxms2rlgr_txwwx6p1g40000gn/T/jieba.cache\n",
      "Loading model cost 1.440 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "xdata,ylabel=get_xdata_label(jieba_getdata) #结巴切词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计词频作为特征\n",
    "count_vec = CountVectorizer() #引入统计词频模块\n",
    "X_count_train = count_vec.fit_transform(xdata) #词频特征 \n",
    "# X_count_data = count_vec.transform(xdata)\n",
    "X_train_count, X_test_count, y_train_count, y_test_count = train_test_split(X_count_train, ylabel, test_size=0.1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_count_train.toarray()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf-idf作为特征\n",
    "tfidf_vec = TfidfVectorizer() #引入tfidf模块\n",
    "X_tfidf_train = tfidf_vec.fit_transform(xdata)  \n",
    "# X_tfidf_data = tfidf_vec.transform(xdata)\n",
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(X_tfidf_train, ylabel, test_size=0.25)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 引入模型\n",
    "SVM_count = svm.SVC(kernel='linear',probability=True)\n",
    "SVM_tfidf = svm.SVC(kernel='linear',probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 准备模型评估特征\n",
    "SVM_count.fit(X_train_count,y_train_count)\n",
    "SVM_tfidf.fit(X_train_tfidf,y_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_count_svm = SVM_count.predict_proba(X_test_count)[:,1]\n",
    "fpr_count_svm, tpr_count_svm, _ = roc_curve(y_test_count, y_pred_count_svm) #roc曲线\n",
    "\n",
    "y_pred_tfidf_svm = SVM_tfidf.predict_proba(X_test_tfidf)[:,1]\n",
    "fpr_tfidf_svm, tpr_tfidf_svm, _ = roc_curve(y_test_tfidf, y_pred_tfidf_svm) #roc曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_count_svm, tpr_count_svm, label='SVM count')\n",
    "plt.plot(fpr_tfidf_svm, tpr_tfidf_svm, label='SVM tfidf')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "print(\"AUC SVM COUNT Score (Train): %f\" % roc_auc_score(y_test_count, y_pred_count_svm))\n",
    "print(\"AUC SVM TFIDF Score (Train): %f\" % roc_auc_score(y_test_tfidf, y_pred_tfidf_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8907, 25803)\n"
     ]
    }
   ],
   "source": [
    "# 上述过程实在是太慢了，速度慢，对于调参也是一大障碍，开始用特征选择\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "print(X_train_count.shape)\n",
    "select_model=SelectKBest(chi2, k=1500)\n",
    "select_model_count = select_model.fit(X_train_count, y_train_count)\n",
    "select_model_tfidf = select_model.fit(X_train_tfidf, y_train_tfidf)\n",
    "\n",
    "X_train_count=select_model_count.transform(X_train_count)\n",
    "X_test_count=select_model_count.transform(X_test_count)\n",
    "\n",
    "X_train_tfidf=select_model_tfidf.transform(X_train_tfidf)\n",
    "X_test_tfidf=select_model_tfidf.transform(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8907, 1500)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_count.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # 特征选择后模型表现\n",
    "SVM_count.fit(X_train_count,y_train_count)\n",
    "SVM_tfidf.fit(X_train_tfidf,y_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid_search 自动调参\n",
    "tuned_parameters = [{'kernel': ['linear'],'C': [0.1, 1, 10],'probability':[True]}]\n",
    "grid_search = GridSearchCV(SVM_count, tuned_parameters, n_jobs=4, cv=3)    \n",
    "grid_search.fit(X_train_count, y_train_count)    \n",
    "best_parameters = grid_search.best_estimator_.get_params()    \n",
    "for para, val in list(best_parameters.items()):    \n",
    "    print(para, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 引入模型和新的参数\n",
    "SVM_count = svm.SVC(kernel='linear',probability=True,C=1)\n",
    "SVM_tfidf = svm.SVC(kernel='linear',probability=True,C=1)\n",
    "SVM_count.fit(X_train_count,y_train_count)\n",
    "SVM_tfidf.fit(X_train_tfidf,y_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_count_svm = SVM_count.predict_proba(X_test_count)[:,1]\n",
    "fpr_count_svm, tpr_count_svm, _ = roc_curve(y_test_count, y_pred_count_svm) #roc曲线\n",
    "\n",
    "y_pred_tfidf_svm = SVM_tfidf.predict_proba(X_test_tfidf)[:,1]\n",
    "fpr_tfidf_svm, tpr_tfidf_svm, _ = roc_curve(y_test_tfidf, y_pred_tfidf_svm) #roc曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_count_svm, tpr_count_svm, label='SVM count')\n",
    "plt.plot(fpr_tfidf_svm, tpr_tfidf_svm, label='SVM tfidf')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "print(\"AUC SVM COUNT Score (Train): %f\" % roc_auc_score(y_test_count, y_pred_count_svm))\n",
    "print(\"AUC SVM TFIDF Score (Train): %f\" % roc_auc_score(y_test_tfidf, y_pred_tfidf_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "from sklearn.externals import joblib\n",
    "model_save=[SVM_count,count_vec,select_model_count]\n",
    "joblib.dump(model_save, 'SVM_COUNT_CLASSIFICATION.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "python37",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
