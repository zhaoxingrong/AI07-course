{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对候选文本构建词向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jieba #安装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /var/folders/_t/wschnxms2rlgr_txwwx6p1g40000gn/T/jieba.cache\n",
      "Loading model cost 1.787 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "全模式分词: \n",
      " 这/ 是/ 一本/ 关于/ 信息/ 检索/ 的/ 书\n"
     ]
    }
   ],
   "source": [
    "# 结巴分词\n",
    "\n",
    "# 第三方分词工具\n",
    "import jieba\n",
    "\n",
    "# 分词模式\n",
    "seg = jieba.cut(\"这是一本关于信息检索的书\", cut_all=True)  # cut_all=True，全模式\n",
    "print(\"\\n全模式分词: \\n\", \"/ \".join(seg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "精确模式分词: \n",
      " 这是/ 一本/ 关于/ 信息/ 检索/ 的/ 书\n"
     ]
    }
   ],
   "source": [
    "seg = jieba.cut(\"这是一本关于信息检索的书\", cut_all=False)  # cut_all=False，精确模式\n",
    "print(\"\\n精确模式分词: \\n\", \"/ \".join(seg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "测试精确模式: \n",
      " 他, 来到, 了, 网易, 杭研, 大厦\n"
     ]
    }
   ],
   "source": [
    "seg = jieba.cut(\"他来到了网易杭研大厦\")  # 默认是精确模式\n",
    "print(\"\\n测试精确模式: \\n\", \", \".join(seg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "测试搜索引擎模式: \n",
      " 小明, 硕士, 毕业, 于, 中国, 科学, 学院, 科学院, 计算, 计算所, ，, 后, 在, 日本, 京都, 大学, 深造\n"
     ]
    }
   ],
   "source": [
    "# 搜索引擎模式\n",
    "seg = jieba.cut_for_search(\"小明硕士毕业于中国科学院计算所，后在日本京都大学深造\")\n",
    "print(\"\\n测试搜索引擎模式: \\n\", \", \".join(seg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['他', '来到', '了', '网易', '杭研', '大厦']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jieba.lcut(\"他来到了网易杭研大厦\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gensim\n",
    "# !pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 示例文本\n",
    "documents = [\"Human machine interface for lab abc computer applications\",\n",
    "             \"A survey of user opinion of computer system response time\",\n",
    "             \"The EPS user interface management system\",\n",
    "             \"System and human system engineering testing of EPS\",              \n",
    "             \"Relation of user perceived response time to error measurement\",\n",
    "             \"The generation of random binary unordered trees\",\n",
    "             \"The intersection graph of paths in trees\",\n",
    "             \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "             \"Graph minors A survey\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove common words and tokenize 去停用词\n",
    "stoplist = set('for a of the and to in'.split())\n",
    "texts = [[word for word in document.lower().split() if word not in stoplist]\n",
    "         for document in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['human', 'machine', 'interface', 'lab', 'abc', 'computer', 'applications'],\n",
       " ['survey', 'user', 'opinion', 'computer', 'system', 'response', 'time'],\n",
       " ['eps', 'user', 'interface', 'management', 'system'],\n",
       " ['system', 'human', 'system', 'engineering', 'testing', 'eps'],\n",
       " ['relation', 'user', 'perceived', 'response', 'time', 'error', 'measurement'],\n",
       " ['generation', 'random', 'binary', 'unordered', 'trees'],\n",
       " ['intersection', 'graph', 'paths', 'trees'],\n",
       " ['graph', 'minors', 'iv', 'widths', 'trees', 'well', 'quasi', 'ordering'],\n",
       " ['graph', 'minors', 'survey']]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove words that appear only once 剔除频次较小的\n",
    "from collections import defaultdict\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "texts = [[token for token in text if frequency[token] > 0] for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['human', 'machine', 'interface', 'lab', 'abc', 'computer', 'applications'],\n",
       " ['survey', 'user', 'opinion', 'computer', 'system', 'response', 'time'],\n",
       " ['eps', 'user', 'interface', 'management', 'system'],\n",
       " ['system', 'human', 'system', 'engineering', 'testing', 'eps'],\n",
       " ['relation', 'user', 'perceived', 'response', 'time', 'error', 'measurement'],\n",
       " ['generation', 'random', 'binary', 'unordered', 'trees'],\n",
       " ['intersection', 'graph', 'paths', 'trees'],\n",
       " ['graph', 'minors', 'iv', 'widths', 'trees', 'well', 'quasi', 'ordering'],\n",
       " ['graph', 'minors', 'survey']]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建字典\n",
    "dictionary = corpora.Dictionary(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abc': 0,\n",
       " 'applications': 1,\n",
       " 'binary': 21,\n",
       " 'computer': 2,\n",
       " 'engineering': 15,\n",
       " 'eps': 13,\n",
       " 'error': 17,\n",
       " 'generation': 22,\n",
       " 'graph': 26,\n",
       " 'human': 3,\n",
       " 'interface': 4,\n",
       " 'intersection': 27,\n",
       " 'iv': 29,\n",
       " 'lab': 5,\n",
       " 'machine': 6,\n",
       " 'management': 14,\n",
       " 'measurement': 18,\n",
       " 'minors': 30,\n",
       " 'opinion': 7,\n",
       " 'ordering': 31,\n",
       " 'paths': 28,\n",
       " 'perceived': 19,\n",
       " 'quasi': 32,\n",
       " 'random': 23,\n",
       " 'relation': 20,\n",
       " 'response': 8,\n",
       " 'survey': 9,\n",
       " 'system': 10,\n",
       " 'testing': 16,\n",
       " 'time': 11,\n",
       " 'trees': 24,\n",
       " 'unordered': 25,\n",
       " 'user': 12,\n",
       " 'well': 33,\n",
       " 'widths': 34}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.token2id #字典的对应关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_doc = \"Human computer intersection Human computer\"\n",
    "new_vec = dictionary.doc2bow(new_doc.lower().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 2), (3, 2), (27, 1)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_vec #第一维词序号，第二维词频次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf-idf in gensim\n",
    "\n",
    "from gensim import models\n",
    "import numpy as np\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "documents = [\"This is the first line\",\n",
    "             \"This is the second sentence\",\n",
    "             \"This third document\"]\n",
    "\n",
    "# Create the Dictionary and Corpus\n",
    "mydict = corpora.Dictionary([simple_preprocess(line) for line in documents])\n",
    "corpus = [mydict.doc2bow(simple_preprocess(line)) for line in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1)],\n",
       " [(1, 1), (3, 1), (4, 1), (5, 1), (6, 1)],\n",
       " [(4, 1), (7, 1), (8, 1)]]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['this', 'is', 'the', 'first', 'line'],\n",
       " ['this', 'is', 'the', 'second', 'sentence'],\n",
       " ['this', 'third', 'document']]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[simple_preprocess(line) for line in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['first', 1], ['is', 1], ['line', 1], ['the', 1], ['this', 1]]\n",
      "[['is', 1], ['the', 1], ['this', 1], ['second', 1], ['sentence', 1]]\n",
      "[['this', 1], ['document', 1], ['third', 1]]\n"
     ]
    }
   ],
   "source": [
    "for doc in corpus:\n",
    "    print([[mydict[id], freq] for id, freq in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = models.TfidfModel(corpus) #构造tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.6633689723434505), (1, 0.2448297500958463), (2, 0.6633689723434505), (3, 0.2448297500958463)]\n",
      "[['first', 0.66], ['is', 0.24], ['line', 0.66], ['the', 0.24]]\n",
      "[(1, 0.2448297500958463), (3, 0.2448297500958463), (5, 0.6633689723434505), (6, 0.6633689723434505)]\n",
      "[['is', 0.24], ['the', 0.24], ['second', 0.66], ['sentence', 0.66]]\n",
      "[(7, 0.7071067811865475), (8, 0.7071067811865475)]\n",
      "[['document', 0.71], ['third', 0.71]]\n"
     ]
    }
   ],
   "source": [
    "for doc in tfidf[corpus]:\n",
    "    print(doc)\n",
    "    print([[mydict[id], np.around(freq, decimals=2)] for id, freq in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0] #代表一段文字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.6633689723434505),\n",
       " (1, 0.2448297500958463),\n",
       " (2, 0.6633689723434505),\n",
       " (3, 0.2448297500958463)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf[corpus[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "## word2vec\n",
    "import gensim\n",
    "from gensim.models import word2vec\n",
    "from gensim.models.word2vec import Text8Corpus\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from multiprocessing import cpu_count\n",
    "# 引入数据集\n",
    "raw_sentences = [\"the quick brown fox jumps over the lazy dogs\",\"yoyoyo you go home now to sleep\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 切分词汇\n",
    "sentences= [s.split() for s in raw_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dogs'],\n",
       " ['yoyoyo', 'you', 'go', 'home', 'now', 'to', 'sleep']]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建模型\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # 忽略warning\n",
    "# 第一种训练方式\n",
    "model = word2vec.Word2Vec(sentences, min_count=1) #训练模型一部到位"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12495872659071369"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 进行相关性比较\n",
    "model.similarity('dogs','you')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 80)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 第二种训练样本\n",
    "new_model = gensim.models.Word2Vec(min_count=1)  # 先启动一个空模型 an empty model\n",
    "new_model.build_vocab(sentences)                 # can be a non-repeatable, 1-pass generator     \n",
    "new_model.train(sentences, total_examples=new_model.corpus_count, epochs=new_model.iter)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12495872659071369"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.similarity('dogs','you')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 存储模型和load模型\n",
    "model.save('newmodel')\n",
    "model = Word2Vec.load('newmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "Word2Vec?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数\n",
    "# · sg： 用于设置训练算法，默认为0，对应CBOW算法；sg=1则采用skip-gram算法，\n",
    "# Skip-gram 是预测一个词的上下文，而 CBOW 是用上下文预测这个词\n",
    "\n",
    "# · size：是指特征向量的维度，默认为100。大的size需要更多的训练数据,但是效果会更好. 推荐值为几十到几百。\n",
    "\n",
    "# ·  window：表示当前词与预测词在一个句子中的最大距离是多少\n",
    "\n",
    "# ·  alpha: 是学习速率\n",
    "\n",
    "# ·  seed：用于随机数发生器。与初始化词向量有关。\n",
    "\n",
    "# ·  min_count: 可以对字典做截断. 词频少于min_count次数的单词会被丢弃掉, 默认值为5\n",
    "\n",
    "# ·  max_vocab_size: 设置词向量构建期间的RAM限制。如果所有独立单词个数超过这个，则就消除掉其中最不频繁的一个。\n",
    "# 每一千万个单词需要大约1GB的RAM。设置成None则没有限制。\n",
    "\n",
    "# ·  sample: 高频词汇的随机降采样的配置阈值，默认为1e-3，范围是(0,1e-5) 解决高频词汇对语义学习的影响\n",
    "\n",
    "# ·  workers参数控制训练的并行数。\n",
    "\n",
    "# ·  hs: 如果为1则会采用hierarchica·softmax技巧。如果设置为0（defau·t），则negative sampling会被使用。\n",
    "#     Hierarchical Softmax： 构建霍夫曼树优化训练\n",
    "\n",
    "# ·  negative: 如果>0,则会采用negativesamp·ing，用于设置多少个noise words\n",
    "\n",
    "# ·  cbow_mean: 如果为0，则采用上下文词向量的和，如果为1（defau·t）则采用均值。只有使用CBOW的时候才起作用。\n",
    "\n",
    "# ·  iter： 迭代次数，默认为5\n",
    "\n",
    "# ·  sorted_vocab： 如果为1（defau·t），则在分配word index 的时候会先对单词基于频率降序排序。\n",
    "\n",
    "# ·  batch_words：每一批的传递给线程的单词的数量，默认为10000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 经典实验重现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = word2vec.Text8Corpus('text8')\n",
    "model = word2vec.Word2Vec(sentences, size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.6396443843841553)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# woman+king-man=?\n",
    "model.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cereal'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 分类不匹配\n",
    "model.doesnt_match(\"breakfast cereal dinner lunch\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6803866155320691"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity('woman', 'man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('woman', 0.6803866624832153),\n",
       " ('girl', 0.6085364818572998),\n",
       " ('creature', 0.5543513298034668),\n",
       " ('person', 0.5219244360923767),\n",
       " ('boy', 0.5174492597579956),\n",
       " ('god', 0.5052016377449036),\n",
       " ('gentleman', 0.4950951933860779),\n",
       " ('evil', 0.4939938485622406),\n",
       " ('men', 0.48556089401245117),\n",
       " ('demon', 0.48267862200737)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 中文实验\n",
    "import jieba\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim.models.word2vec as w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jieba_cut(input_file,output_file):\n",
    "#     input_file='ming.txt'\n",
    "#     output_file='mimg_cut.txt'\n",
    "    read_file = open(input_file, 'r',encoding='gbk')\n",
    "    write_file = open(output_file, 'w')  \n",
    "    stop_set=set(pd.read_table('chinese-stopword.txt',sep='\\t',names=['stop'])['stop']) #停用词集合\n",
    "    line = read_file.readline()\n",
    "    while line:\n",
    "        new_line=' '.join([i  for i in jieba.lcut(line) if i not in stop_set])\n",
    "        write_file.write(new_line)\n",
    "        try:\n",
    "            line = read_file.readline()\n",
    "        except:\n",
    "            continue\n",
    "    read_file.close()  \n",
    "    write_file.close() \n",
    "    return output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file='ming.txt'\n",
    "output_file='mimg_cut.txt'\n",
    "model_file_name = get_jieba_cut(input_file,output_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = w2v.LineSentence(model_file_name)  \n",
    "model = w2v.Word2Vec(sentences, sg=1, size=128, window=4, min_count=5)   # 训练\n",
    "model.save('MING.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('明', 0.7663540840148926),\n",
       " ('违反', 0.7517389059066772),\n",
       " ('朱棣', 0.7467007040977478),\n",
       " ('胡惟庸', 0.7379322052001953),\n",
       " ('执行', 0.7352919578552246),\n",
       " ('废除', 0.7352467775344849),\n",
       " ('神宗', 0.7338056564331055),\n",
       " ('英明', 0.7274527549743652),\n",
       " ('制定', 0.7247770428657532),\n",
       " ('认为', 0.7236449122428894)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(['朱元璋'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7467007066937742"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity('朱元璋', '朱棣')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('朱棣', 0.7286109924316406)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['朱元璋', '李善长'], negative=['姚广孝'], topn=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0175992 ,  0.44323987, -0.14571258,  0.03201498, -0.3462972 ,\n",
       "       -0.24746361,  0.32770607,  0.2853709 , -0.1782051 ,  0.13410571,\n",
       "        0.23685698,  0.11023909, -0.08236469, -0.34068906, -0.02337989,\n",
       "       -0.06848098, -0.1595218 ,  0.10898316,  0.0674423 ,  0.05590528,\n",
       "        0.2514578 , -0.00262522, -0.38643047, -0.0447476 , -0.33601537,\n",
       "       -0.09811483, -0.05430719, -0.11418302, -0.11787904, -0.05881744,\n",
       "       -0.14421795,  0.06666927,  0.1450599 , -0.16674645, -0.12227491,\n",
       "        0.19156083,  0.03522585, -0.05072409, -0.12803306,  0.1441473 ,\n",
       "       -0.01934806, -0.08413758, -0.04167783, -0.09034103,  0.12232478,\n",
       "        0.2854216 , -0.19457704, -0.3737419 , -0.23143405, -0.13324578,\n",
       "       -0.00424377,  0.2907174 ,  0.14718641, -0.10354549, -0.09355155,\n",
       "       -0.10434806, -0.16471006, -0.05543605, -0.25707617,  0.2475568 ,\n",
       "        0.28524083,  0.06145659,  0.11175146,  0.30072367,  0.06306344,\n",
       "        0.0173163 ,  0.14386146,  0.14548387, -0.18373454,  0.32681465,\n",
       "        0.12865113,  0.10715888, -0.03404541, -0.20959051, -0.01432001,\n",
       "        0.25559264,  0.01818975,  0.00052122, -0.10303541,  0.50290245,\n",
       "        0.09348455,  0.15667486,  0.22552598, -0.18834569,  0.11842396,\n",
       "        0.07596536,  0.31526262, -0.17223653,  0.05589828,  0.26564   ,\n",
       "        0.3772093 ,  0.11126185,  0.24486256,  0.19548899, -0.00256508,\n",
       "        0.4963642 ,  0.16715325, -0.27985543, -0.13887604,  0.11434761,\n",
       "       -0.10559598,  0.35732546, -0.13894318,  0.05112936, -0.00596572,\n",
       "        0.13257208,  0.0067288 , -0.4386047 ,  0.11487974,  0.17621155,\n",
       "       -0.11028238, -0.10008398,  0.13025823,  0.12503858,  0.24682543,\n",
       "        0.04361019, -0.19650298,  0.25695685,  0.22437072,  0.12324198,\n",
       "        0.16413319,  0.1271108 , -0.18734312,  0.23210616,  0.37161785,\n",
       "       -0.06641548,  0.13992977, -0.02631798], dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['朱元璋'] #获取词向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__ignoreds',\n",
       " '__init__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__numpys',\n",
       " '__recursive_saveloads',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__scipys',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slotnames__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_adapt_by_suffix',\n",
       " '_check_training_sanity',\n",
       " '_clear_post_train',\n",
       " '_do_train_job',\n",
       " '_get_job_params',\n",
       " '_get_thread_working_mem',\n",
       " '_job_producer',\n",
       " '_load_specials',\n",
       " '_log_epoch_end',\n",
       " '_log_epoch_progress',\n",
       " '_log_progress',\n",
       " '_log_train_end',\n",
       " '_minimize_model',\n",
       " '_raw_word_count',\n",
       " '_save_specials',\n",
       " '_set_train_params',\n",
       " '_smart_save',\n",
       " '_train_epoch',\n",
       " '_update_job_params',\n",
       " '_worker_loop',\n",
       " 'accuracy',\n",
       " 'alpha',\n",
       " 'batch_words',\n",
       " 'build_vocab',\n",
       " 'build_vocab_from_freq',\n",
       " 'callbacks',\n",
       " 'cbow_mean',\n",
       " 'clear_sims',\n",
       " 'compute_loss',\n",
       " 'corpus_count',\n",
       " 'cum_table',\n",
       " 'delete_temporary_training_data',\n",
       " 'doesnt_match',\n",
       " 'epochs',\n",
       " 'estimate_memory',\n",
       " 'evaluate_word_pairs',\n",
       " 'get_latest_training_loss',\n",
       " 'hashfxn',\n",
       " 'hs',\n",
       " 'init_sims',\n",
       " 'intersect_word2vec_format',\n",
       " 'iter',\n",
       " 'layer1_size',\n",
       " 'load',\n",
       " 'load_word2vec_format',\n",
       " 'log_accuracy',\n",
       " 'min_alpha',\n",
       " 'min_alpha_yet_reached',\n",
       " 'min_count',\n",
       " 'model_trimmed_post_training',\n",
       " 'most_similar',\n",
       " 'most_similar_cosmul',\n",
       " 'n_similarity',\n",
       " 'negative',\n",
       " 'predict_output_word',\n",
       " 'random',\n",
       " 'reset_from',\n",
       " 'running_training_loss',\n",
       " 'sample',\n",
       " 'save',\n",
       " 'save_word2vec_format',\n",
       " 'score',\n",
       " 'sg',\n",
       " 'similar_by_vector',\n",
       " 'similar_by_word',\n",
       " 'similarity',\n",
       " 'syn0_lockf',\n",
       " 'syn1',\n",
       " 'syn1neg',\n",
       " 'total_train_time',\n",
       " 'train',\n",
       " 'train_count',\n",
       " 'trainables',\n",
       " 'vector_size',\n",
       " 'vocabulary',\n",
       " 'window',\n",
       " 'wmdistance',\n",
       " 'workers',\n",
       " 'wv']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
