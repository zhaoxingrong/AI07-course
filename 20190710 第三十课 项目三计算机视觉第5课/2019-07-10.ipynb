{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-06fffa32dec3>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/deepglint/miniconda2/envs/python3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/deepglint/miniconda2/envs/python3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /Users/deepglint/miniconda2/envs/python3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /Users/deepglint/miniconda2/envs/python3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/deepglint/miniconda2/envs/python3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/deepglint/miniconda2/envs/python3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist=input_data.read_data_sets('./MNIST_data',one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.validation.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,train_y=mnist.train.next_batch(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y#One_Hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x,test_y=mnist.test.next_batch(5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 图像的可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rc('image',cmap='binary')\n",
    "for i in range(10):\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.imshow(train_x[i].reshape(28,28))\n",
    "    print(train_y[i])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全连接神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model1():\n",
    "    model=Sequential()\n",
    "    model.add(Dense(784,activation='relu'))\n",
    "    model.add(Dense(100,activation='relu'))\n",
    "    model.add(Dense(100,activation='relu'))\n",
    "    model.add(Dense(10,activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=model1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.compile(optimizer='adam',loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "20000/20000 [==============================] - 3s 152us/step - loss: 0.0310\n",
      "Epoch 2/2\n",
      "20000/20000 [==============================] - 3s 149us/step - loss: 0.0308\n"
     ]
    }
   ],
   "source": [
    "history=m.fit(train_x,train_y,epochs=2,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=m.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.952"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(pred.argmax(1),test_y.argmax(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D,MaxPool2D,Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当前的所有input是784*1的，如果使用卷积神经网络需要进行resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_img=train_x.reshape(train_x.shape[0],28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_img=test_x.reshape(test_x.shape[0],28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model2():\n",
    "    model=Sequential()\n",
    "    model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28,28,1)))\n",
    "    model.add(MaxPool2D())\n",
    "    model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=model2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.compile(optimizer='adam',loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "20000/20000 [==============================] - 10s 522us/step - loss: 0.2597\n",
      "Epoch 2/2\n",
      "20000/20000 [==============================] - 13s 631us/step - loss: 0.0810\n"
     ]
    }
   ],
   "source": [
    "history=m.fit(X_train_img,train_y,epochs=2,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=m.predict(X_test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.977"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(pred.argmax(1),test_y.argmax(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.1'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import random\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 图像的Normalize\n",
    "\n",
    "每个像素-mean/std\n",
    "\n",
    "每个像素的归一化缩放\n",
    "\n",
    "思考:\n",
    "\n",
    "1.归一化哪部分数据？A训练集、B评测集、C训练集+评测集 -> C\n",
    "\n",
    "2.归一化的参数mean和std来自于？A训练集、B评测集、C训练集+评测集 -> A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13070042"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(mnist.train.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3081594"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(mnist.train.images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据的归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trans=transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,),(0.3081,))#参数mean和std来自于训练集，但是transform本身在训练和评测的时候都会使用\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=datasets.MNIST('data',train=True,download=True,transform=data_trans)\n",
    "test_data=datasets.MNIST('data',train=False,download=True,transform=data_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train=int(len(train_data)*0.9)\n",
    "n_validation=len(train_data)-n_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,valid_data=torch.utils.data.random_split(train_data,[n_train,n_validation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54000"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Split: train\n",
       "    Root Location: data\n",
       "    Transforms (if any): Compose(\n",
       "                             Resize(size=32, interpolation=PIL.Image.BILINEAR)\n",
       "                             ToTensor()\n",
       "                             Normalize(mean=(0.1307,), std=(0.3081,))\n",
       "                         )\n",
       "    Target Transforms (if any): None"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "目前完成了数据集的制作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator=torch.utils.data.DataLoader(train_data,shuffle=True,batch_size=batch_size)\n",
    "valid_iterator=torch.utils.data.DataLoader(valid_data,batch_size=batch_size)\n",
    "test_iterator=torch.utils.data.DataLoader(test_data,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "844"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 构建神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet,self).__init__()\n",
    "        #第一层conv1，因为是MNIST数据集，所有channel数是1，输出的channel是6,kernel_size是5*5\n",
    "        self.conv1=nn.Conv2d(1,6,5)\n",
    "        #第二层conv2,输入channel=6,输出channel=16，kernel5*5,input_size=14*14,output_size=10*10\n",
    "        self.conv2=nn.Conv2d(6,16,5)\n",
    "        \n",
    "        self.fc1=nn.Linear(16*5*5,120)\n",
    "        \n",
    "        self.fc2=nn.Linear(120,84)\n",
    "        \n",
    "        self.fc3=nn.Linear(84,10)#不用增加softmax层，从推断的角度直接使用argmax就可以得到最终的预测结果，在cross_entropy函数中实现了softmax的功能\n",
    "        \n",
    "    def forward(self,x):#规定计算图架构\n",
    "        out=F.max_pool2d(F.relu(self.conv1(x)),2)\n",
    "        out=F.max_pool2d(F.relu(self.conv2(out)),2)\n",
    "        out=out.view(out.shape[0],-1)\n",
    "        out=F.relu(self.fc1(out))\n",
    "        out=F.relu(self.fc2(out))\n",
    "        out=self.fc3(out)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 载入模型并进行计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir='models'\n",
    "\n",
    "if not os.path.isdir(model_dir):\n",
    "    os.makedirs(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=LeNet().to(device)#将神经网络对象加载到相应的内存或显存中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path=os.path.join(model_dir,'lenet_mnist.pt')#保存训练好的模型的位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accu(fx,y):\n",
    "    pred=fx.max(1,keepdim=True)[1]\n",
    "    correct=pred.eq(y.view_as(pred)).sum()\n",
    "    acc=correct.float()/pred.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练一个epoch\n",
    "def train(model,device,iterator,optimizer,criterion):\n",
    "    epoch_loss=0#积累变量\n",
    "    epoch_acc=0#积累变量\n",
    "    model.train()#该函数表示PHASE=Train,自动求导以及求导运算将会被激活\n",
    "    \n",
    "    for (x,y) in iterator:#拿每一个minibatch\n",
    "#         print(x,y)\n",
    "        x=x.to(device)\n",
    "        y=y.to(device)\n",
    "        optimizer.zero_grad()#将所有的梯度变量清零\n",
    "        fx=model(x)#进行inference\n",
    "        loss=criterion(fx,y)#计算train_loss\n",
    "        acc=accu(fx,y)#计算train_acc\n",
    "        loss.backward()#进行bp回算各参数和神经元的梯度\n",
    "        optimizer.step()#统一进行梯度下降的更新\n",
    "        epoch_loss+=loss.item()\n",
    "        epoch_acc+=acc.item()\n",
    "    \n",
    "    #返回平均训练Loss和平均训练Accu\n",
    "    return epoch_loss/len(iterator),epoch_acc/len(iterator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "#评测一个验证集，不用梯度下降，只是进行推断和误差计算\n",
    "def evaluate(model,device,iterator,criterion):\n",
    "    epoch_loss=0\n",
    "    epoch_acc=0\n",
    "    model.eval()#PHASE=Eval,不会增加梯度的存储变量和计算单元\n",
    "    with torch.no_grad():\n",
    "        for (x,y) in iterator:\n",
    "            x=x.to(device)\n",
    "            y=y.to(device)\n",
    "            fx=model(x)\n",
    "            loss=criterion(fx,y)\n",
    "            acc=accu(fx,y)\n",
    "            epoch_loss+=loss.item()\n",
    "            epoch_acc+=acc.item()\n",
    "            \n",
    "    return epoch_loss/len(iterator),epoch_acc/len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_valid_loss=float('inf')#自动筛选最优模型并保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1|Train Loss:0.0266898773517901|Train Acc:0.9912618483412322|Val Loss:0.042157018425140004|Val Acc:0.9876994680851063\n",
      "Epoch:2|Train Loss:0.023265801414972066|Train Acc:0.992391143364929|Val Loss:0.04200601065206277|Val Acc:0.987533244680851\n",
      "Epoch:3|Train Loss:0.019364272754074416|Train Acc:0.9937919628987381|Val Loss:0.04667131786381434|Val Acc:0.9873670212765957\n",
      "Epoch:4|Train Loss:0.01695843954996528|Train Acc:0.9943905509478673|Val Loss:0.04073276849645636|Val Acc:0.9878656914893617\n",
      "Epoch:5|Train Loss:0.013955614088906358|Train Acc:0.9954457938388626|Val Loss:0.05334185337291119|Val Acc:0.9867021276595744\n",
      "Epoch:6|Train Loss:0.014754624299371783|Train Acc:0.9951866113744076|Val Loss:0.037643225546529956|Val Acc:0.9901928191489362\n",
      "Epoch:7|Train Loss:0.011473359045753547|Train Acc:0.996149289099526|Val Loss:0.04160339607861193|Val Acc:0.9895279255319149\n",
      "Epoch:8|Train Loss:0.01147592620332659|Train Acc:0.996032039912956|Val Loss:0.045265191042686795|Val Acc:0.9893617021276596\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    train_loss,train_acc=train(model,device,train_iterator,optimizer,criterion)\n",
    "    valid_loss,valid_acc=evaluate(model,device,valid_iterator,criterion)\n",
    "    if valid_loss<best_valid_loss:#当前模型好于历史最好模型\n",
    "        best_valid_loss=valid_loss\n",
    "        torch.save(model.state_dict(),model_path)#模型文件的更新\n",
    "    print('Epoch:{0}|Train Loss:{1}|Train Acc:{2}|Val Loss:{3}|Val Acc:{4}'.format(epoch+1,train_loss,train_acc,valid_loss,valid_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(model_path))#load最好结果到model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss,test_acc=evaluate(model,device,test_iterator,criterion)\n",
    "print('Test Loss:{0}|Test Acc:{1}'.format(test_loss,test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
